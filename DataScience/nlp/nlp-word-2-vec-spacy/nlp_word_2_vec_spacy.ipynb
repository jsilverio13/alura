{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-word-2-vec-spacy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Spacy e Arquivos"
      ],
      "metadata": {
        "id": "_KIHIt5ehJN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MWJFOdoMM-9",
        "outputId": "d4beab57-0d76-4719-8903-e3c97972100b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-py3-none-any.whl size=21186281 sha256=341203cce94d99f4f51c619d3af429bc90571528b039f491ce650ecbb612340f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2fd53vgr/wheels/c3/f9/0c/5c014a36941a00f5df5fc0756cb961d7c457a978e697a6ce3b\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhYVYWY_qmPJ",
        "outputId": "962dca7d-56a5-4e84-dede-7450de34cc50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip -O > cbow_s300.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  886M  100  886M    0     0  7656k      0  0:01:58  0:01:58 --:--:-- 6205k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/skip_s300.zip -O  > skip_s300.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izN3diVpKKh0",
        "outputId": "ced319e7-4750-4b42-96ea-e26091c4c8a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  914M  100  914M    0     0  10.4M      0  0:01:27  0:01:27 --:--:-- 11.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip skip_s300.zip\n",
        "!unzip cbow_s300.zip"
      ],
      "metadata": {
        "id": "-YM4aTV3IYCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57694ddd-b30b-4d0f-f3ad-25365005af4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  skip_s300.zip\n",
            "  inflating: skip_s300.txt           \n",
            "Archive:  cbow_s300.zip\n",
            "  inflating: cbow_s300.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy e Import "
      ],
      "metadata": {
        "id": "m7e0z6OihUi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy"
      ],
      "metadata": {
        "id": "Xnu1jAiyMX5r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ],
      "metadata": {
        "id": "kUwE0mOILPF2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bd0ILj6vDPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5230315c-1fb3-4926-ba35-2f684479c004"
      },
      "source": [
        "uri_treino = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/treino.csv'\n",
        "uri_teste = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/teste.csv'\n",
        "dados_treino = pd.read_csv(uri_treino)\n",
        "dados_teste = pd.read_csv(uri_teste)\n",
        "dados_treino.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74614544-cae8-4861-ab00-7e97eb0106ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74136</th>\n",
              "      <td>Ex-sócios da XP se unem para apostar no setor ...</td>\n",
              "      <td>Ex-sócios de peso da XP compraram uma fatia de...</td>\n",
              "      <td>2017-06-08</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88662</th>\n",
              "      <td>Posso doar as coisas dos outros?</td>\n",
              "      <td>A mãe de uma menina de sete anos contou que a ...</td>\n",
              "      <td>2015-09-05</td>\n",
              "      <td>colunas</td>\n",
              "      <td>quebracabeca</td>\n",
              "      <td>http://www1.folha.uol.com.br/colunas/quebracab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12791</th>\n",
              "      <td>Comissão da UE propõe empréstimo de curto praz...</td>\n",
              "      <td>A Comissão Europeia está propondo conceder um ...</td>\n",
              "      <td>2015-07-15</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2015/07/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46378</th>\n",
              "      <td>Tegucigalpa</td>\n",
              "      <td>- Uma água. R$2,50. Mais alguma coisa, senhor?...</td>\n",
              "      <td>2015-10-18</td>\n",
              "      <td>colunas</td>\n",
              "      <td>antonioprata</td>\n",
              "      <td>http://www1.folha.uol.com.br/colunas/antoniopr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85649</th>\n",
              "      <td>Acidente com avião militar em base aérea na Es...</td>\n",
              "      <td>A queda de um avião militar F-16 da Grécia dei...</td>\n",
              "      <td>2015-01-26</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2015/01/158...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74614544-cae8-4861-ab00-7e97eb0106ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74614544-cae8-4861-ab00-7e97eb0106ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74614544-cae8-4861-ab00-7e97eb0106ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "74136  Ex-sócios da XP se unem para apostar no setor ...   \n",
              "88662                   Posso doar as coisas dos outros?   \n",
              "12791  Comissão da UE propõe empréstimo de curto praz...   \n",
              "46378                                        Tegucigalpa   \n",
              "85649  Acidente com avião militar em base aérea na Es...   \n",
              "\n",
              "                                                    text        date category  \\\n",
              "74136  Ex-sócios de peso da XP compraram uma fatia de...  2017-06-08  mercado   \n",
              "88662  A mãe de uma menina de sete anos contou que a ...  2015-09-05  colunas   \n",
              "12791  A Comissão Europeia está propondo conceder um ...  2015-07-15  mercado   \n",
              "46378  - Uma água. R$2,50. Mais alguma coisa, senhor?...  2015-10-18  colunas   \n",
              "85649  A queda de um avião militar F-16 da Grécia dei...  2015-01-26    mundo   \n",
              "\n",
              "        subcategory                                               link  \n",
              "74136           NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  \n",
              "88662  quebracabeca  http://www1.folha.uol.com.br/colunas/quebracab...  \n",
              "12791           NaN  http://www1.folha.uol.com.br/mercado/2015/07/1...  \n",
              "46378  antonioprata  http://www1.folha.uol.com.br/colunas/antoniopr...  \n",
              "85649           NaN  http://www1.folha.uol.com.br/mundo/2015/01/158...  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gerando Modelo"
      ],
      "metadata": {
        "id": "DYD-HBI9OJDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
        "doc = nlp(texto)"
      ],
      "metadata": {
        "id": "jJGMal7aLPY2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "id": "ogH04VNCLRO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59879c79-1893-4218-d87e-787c50459787"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rio de Janeiro é uma cidade maravilhosa"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[2])"
      ],
      "metadata": {
        "id": "jE1S8i85LSmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260fb3c7-5a64-493f-d5cd-c3e35b653d78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])"
      ],
      "metadata": {
        "id": "RAOq8b6-Lqq3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trata_textos(doc):\n",
        "    tokens_validos = []\n",
        "    for token in doc:\n",
        "        e_valido = not token.is_stop and token.is_alpha\n",
        "        if e_valido:\n",
        "            tokens_validos.append(token.text)\n",
        "\n",
        "    if len(tokens_validos) > 2:\n",
        "        return  \" \".join(tokens_validos)\n",
        "\n",
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)"
      ],
      "metadata": {
        "id": "A3o2Y9bVLsZB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)"
      ],
      "metadata": {
        "id": "r1Mj70dcLx5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8c90fdf4-eaeb-486d-83c6-fa6c269a3d3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "t0 = time()\n",
        "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
        "                                                        batch_size = 1000,\n",
        "                                                        n_process = -1)]\n",
        "\n",
        "tf = time() - t0\n",
        "\n",
        "print(tf/60)"
      ],
      "metadata": {
        "id": "4FL--YNrLzZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c9f50e-f066-457f-f120-883ca421d508"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.28319814602534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
        "titulos_tratados.head()"
      ],
      "metadata": {
        "id": "J_LNns61L0p9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75a7d6b7-bddc-4792-8a2e-7fa19972c31d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-faec790c-8f98-44d2-82f1-732ba33feb14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>macron e le pen a o turno frança revés siglas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>governo antecipa balanço e alckmin anuncia que...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>queda maio a atividade econômica sobe junho bc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faec790c-8f98-44d2-82f1-732ba33feb14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faec790c-8f98-44d2-82f1-732ba33feb14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faec790c-8f98-44d2-82f1-732ba33feb14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              titulo\n",
              "0  polêmica marine le pen abomina negacionistas h...\n",
              "1  macron e le pen a o turno frança revés siglas ...\n",
              "2  apesar larga vitória legislativas macron terá ...\n",
              "3  governo antecipa balanço e alckmin anuncia que...\n",
              "4     queda maio a atividade econômica sobe junho bc"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)"
      ],
      "metadata": {
        "id": "7bTUUbWDMfwD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo"
      ],
      "metadata": {
        "id": "1u_5gclDMldu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb4a42f-98e6-44c0-fa74-2a2dda0f33ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7fbeb6214890>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(titulos_tratados))\n",
        "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
        "print(len(titulos_tratados))"
      ],
      "metadata": {
        "id": "2YJzg5fhMmc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ffd8bd-b72a-422c-ddc9-b7134db0339d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90000\n",
            "86113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
      ],
      "metadata": {
        "id": "X5VUw5PIMnaL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
      ],
      "metadata": {
        "id": "kn4Llxg9Moaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54f04ce-34c2-44d2-ad84-83974c470113"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:38:31,840 : - collecting all words and their counts\n",
            "2022-03-07 22:38:31,843 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-03-07 22:38:31,866 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2022-03-07 22:38:31,882 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2022-03-07 22:38:31,897 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2022-03-07 22:38:31,913 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2022-03-07 22:38:31,930 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2022-03-07 22:38:31,952 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2022-03-07 22:38:31,971 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2022-03-07 22:38:31,992 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2022-03-07 22:38:32,022 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2022-03-07 22:38:32,044 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2022-03-07 22:38:32,065 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2022-03-07 22:38:32,085 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2022-03-07 22:38:32,112 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2022-03-07 22:38:32,135 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2022-03-07 22:38:32,157 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2022-03-07 22:38:32,180 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2022-03-07 22:38:32,203 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2022-03-07 22:38:32,212 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2022-03-07 22:38:32,215 : - Loading a fresh vocabulary\n",
            "2022-03-07 22:38:32,430 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2022-03-07 22:38:32,433 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2022-03-07 22:38:32,485 : - deleting the raw counts dictionary of 39968 items\n",
            "2022-03-07 22:38:32,489 : - sample=0.001 downsamples 11 most-common words\n",
            "2022-03-07 22:38:32,490 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2022-03-07 22:38:32,563 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2022-03-07 22:38:32,566 : - resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(w2v_modelo)"
      ],
      "metadata": {
        "id": "d3hMFaShMphU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0263022e-8062-49cf-8763-7635edb5826a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_adapt_by_suffix',\n",
              " '_check_input_data_sanity',\n",
              " '_check_training_sanity',\n",
              " '_clear_post_train',\n",
              " '_do_train_epoch',\n",
              " '_do_train_job',\n",
              " '_get_job_params',\n",
              " '_get_thread_working_mem',\n",
              " '_job_producer',\n",
              " '_load_specials',\n",
              " '_log_epoch_end',\n",
              " '_log_epoch_progress',\n",
              " '_log_progress',\n",
              " '_log_train_end',\n",
              " '_minimize_model',\n",
              " '_raw_word_count',\n",
              " '_save_specials',\n",
              " '_set_train_params',\n",
              " '_smart_save',\n",
              " '_train_epoch',\n",
              " '_train_epoch_corpusfile',\n",
              " '_update_job_params',\n",
              " '_worker_loop',\n",
              " '_worker_loop_corpusfile',\n",
              " 'accuracy',\n",
              " 'alpha',\n",
              " 'batch_words',\n",
              " 'build_vocab',\n",
              " 'build_vocab_from_freq',\n",
              " 'callbacks',\n",
              " 'cbow_mean',\n",
              " 'clear_sims',\n",
              " 'compute_loss',\n",
              " 'corpus_count',\n",
              " 'corpus_total_words',\n",
              " 'cum_table',\n",
              " 'delete_temporary_training_data',\n",
              " 'doesnt_match',\n",
              " 'epochs',\n",
              " 'estimate_memory',\n",
              " 'evaluate_word_pairs',\n",
              " 'get_latest_training_loss',\n",
              " 'hashfxn',\n",
              " 'hs',\n",
              " 'init_sims',\n",
              " 'intersect_word2vec_format',\n",
              " 'iter',\n",
              " 'layer1_size',\n",
              " 'load',\n",
              " 'load_word2vec_format',\n",
              " 'log_accuracy',\n",
              " 'max_final_vocab',\n",
              " 'min_alpha',\n",
              " 'min_alpha_yet_reached',\n",
              " 'min_count',\n",
              " 'model_trimmed_post_training',\n",
              " 'most_similar',\n",
              " 'most_similar_cosmul',\n",
              " 'n_similarity',\n",
              " 'negative',\n",
              " 'ns_exponent',\n",
              " 'predict_output_word',\n",
              " 'random',\n",
              " 'reset_from',\n",
              " 'running_training_loss',\n",
              " 'sample',\n",
              " 'save',\n",
              " 'save_word2vec_format',\n",
              " 'score',\n",
              " 'sg',\n",
              " 'similar_by_vector',\n",
              " 'similar_by_word',\n",
              " 'similarity',\n",
              " 'syn0_lockf',\n",
              " 'syn1',\n",
              " 'syn1neg',\n",
              " 'total_train_time',\n",
              " 'train',\n",
              " 'train_count',\n",
              " 'trainables',\n",
              " 'vector_size',\n",
              " 'vocabulary',\n",
              " 'window',\n",
              " 'wmdistance',\n",
              " 'workers',\n",
              " 'wv']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.corpus_count"
      ],
      "metadata": {
        "id": "rOC1xTQbM1ms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ce060c-63d1-4b05-8652-0bd120f11fa0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86113"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo.corpus_count,\n",
        "                 epochs = 30)"
      ],
      "metadata": {
        "id": "rnEtiP4_M3X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85414b29-472d-46d8-ab22-c62f137f0804"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:38:35,518 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
            "2022-03-07 22:38:36,561 : - EPOCH 1 - PROGRESS: at 56.93% examples, 285033 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:37,146 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:37,181 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:37,184 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:37,187 : - EPOCH - 1 : training on 597929 raw words (502902 effective words) took 1.6s, 308979 effective words/s\n",
            "2022-03-07 22:38:38,254 : - EPOCH 2 - PROGRESS: at 61.95% examples, 297646 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:38,749 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:38,770 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:38,778 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:38,779 : - EPOCH - 2 : training on 597929 raw words (502720 effective words) took 1.6s, 320095 effective words/s\n",
            "2022-03-07 22:38:39,825 : - EPOCH 3 - PROGRESS: at 68.61% examples, 334074 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:38:40,247 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:40,253 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:40,263 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:40,264 : - EPOCH - 3 : training on 597929 raw words (502882 effective words) took 1.5s, 341921 effective words/s\n",
            "2022-03-07 22:38:41,315 : - EPOCH 4 - PROGRESS: at 66.92% examples, 324651 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:41,745 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:41,748 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:41,765 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:41,766 : - EPOCH - 4 : training on 597929 raw words (502991 effective words) took 1.5s, 338153 effective words/s\n",
            "2022-03-07 22:38:42,809 : - EPOCH 5 - PROGRESS: at 68.61% examples, 334887 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:43,195 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:43,233 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:43,243 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:43,245 : - EPOCH - 5 : training on 597929 raw words (503052 effective words) took 1.5s, 343341 effective words/s\n",
            "2022-03-07 22:38:44,271 : - EPOCH 6 - PROGRESS: at 65.27% examples, 324273 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:44,705 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:44,747 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:44,752 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:44,755 : - EPOCH - 6 : training on 597929 raw words (502903 effective words) took 1.5s, 336346 effective words/s\n",
            "2022-03-07 22:38:45,785 : - EPOCH 7 - PROGRESS: at 65.27% examples, 323896 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:46,218 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:46,251 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:46,260 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:46,263 : - EPOCH - 7 : training on 597929 raw words (502983 effective words) took 1.5s, 337454 effective words/s\n",
            "2022-03-07 22:38:47,279 : - EPOCH 8 - PROGRESS: at 61.92% examples, 310934 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:47,786 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:47,798 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:47,812 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:47,814 : - EPOCH - 8 : training on 597929 raw words (503034 effective words) took 1.5s, 327382 effective words/s\n",
            "2022-03-07 22:38:48,845 : - EPOCH 9 - PROGRESS: at 66.94% examples, 329077 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:49,270 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:49,283 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:49,295 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:49,296 : - EPOCH - 9 : training on 597929 raw words (502590 effective words) took 1.5s, 341388 effective words/s\n",
            "2022-03-07 22:38:50,322 : - EPOCH 10 - PROGRESS: at 68.59% examples, 339665 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:50,695 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:50,713 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:50,727 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:50,728 : - EPOCH - 10 : training on 597929 raw words (503058 effective words) took 1.4s, 353981 effective words/s\n",
            "2022-03-07 22:38:51,754 : - EPOCH 11 - PROGRESS: at 65.27% examples, 323919 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:38:52,161 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:52,167 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:52,200 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:52,202 : - EPOCH - 11 : training on 597929 raw words (502754 effective words) took 1.5s, 344245 effective words/s\n",
            "2022-03-07 22:38:53,238 : - EPOCH 12 - PROGRESS: at 66.93% examples, 329481 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:53,641 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:53,655 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:53,663 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:53,664 : - EPOCH - 12 : training on 597929 raw words (502820 effective words) took 1.4s, 347510 effective words/s\n",
            "2022-03-07 22:38:54,690 : - EPOCH 13 - PROGRESS: at 66.94% examples, 332277 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:38:55,117 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:55,129 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:55,139 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:55,140 : - EPOCH - 13 : training on 597929 raw words (502962 effective words) took 1.5s, 343869 effective words/s\n",
            "2022-03-07 22:38:56,169 : - EPOCH 14 - PROGRESS: at 65.27% examples, 322905 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:38:56,600 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:56,620 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:56,634 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:56,636 : - EPOCH - 14 : training on 597929 raw words (502940 effective words) took 1.5s, 339270 effective words/s\n",
            "2022-03-07 22:38:57,683 : - EPOCH 15 - PROGRESS: at 65.27% examples, 318295 words/s, in_qsize 6, out_qsize 2\n",
            "2022-03-07 22:38:58,092 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:58,114 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:58,118 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:58,120 : - EPOCH - 15 : training on 597929 raw words (503003 effective words) took 1.5s, 342752 effective words/s\n",
            "2022-03-07 22:38:59,172 : - EPOCH 16 - PROGRESS: at 68.61% examples, 331789 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:38:59,558 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:38:59,569 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:38:59,590 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:38:59,591 : - EPOCH - 16 : training on 597929 raw words (502829 effective words) took 1.5s, 344787 effective words/s\n",
            "2022-03-07 22:39:00,631 : - EPOCH 17 - PROGRESS: at 68.60% examples, 335438 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:39:01,003 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:01,017 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:01,024 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:01,027 : - EPOCH - 17 : training on 597929 raw words (502697 effective words) took 1.4s, 353232 effective words/s\n",
            "2022-03-07 22:39:02,057 : - EPOCH 18 - PROGRESS: at 66.94% examples, 330770 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:02,474 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:02,481 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:02,493 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:02,494 : - EPOCH - 18 : training on 597929 raw words (502940 effective words) took 1.5s, 345806 effective words/s\n",
            "2022-03-07 22:39:03,553 : - EPOCH 19 - PROGRESS: at 66.92% examples, 322896 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:03,963 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:03,971 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:03,974 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:03,981 : - EPOCH - 19 : training on 597929 raw words (502817 effective words) took 1.5s, 342181 effective words/s\n",
            "2022-03-07 22:39:05,009 : - EPOCH 20 - PROGRESS: at 68.61% examples, 339081 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:39:05,390 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:05,402 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:05,419 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:05,420 : - EPOCH - 20 : training on 597929 raw words (503005 effective words) took 1.4s, 352283 effective words/s\n",
            "2022-03-07 22:39:06,433 : - EPOCH 21 - PROGRESS: at 65.27% examples, 327499 words/s, in_qsize 6, out_qsize 1\n",
            "2022-03-07 22:39:06,881 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:06,889 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:06,914 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:06,915 : - EPOCH - 21 : training on 597929 raw words (502746 effective words) took 1.5s, 338966 effective words/s\n",
            "2022-03-07 22:39:07,934 : - EPOCH 22 - PROGRESS: at 65.27% examples, 327479 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:39:08,355 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:08,372 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:08,384 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:08,386 : - EPOCH - 22 : training on 597929 raw words (502983 effective words) took 1.5s, 346108 effective words/s\n",
            "2022-03-07 22:39:09,426 : - EPOCH 23 - PROGRESS: at 66.94% examples, 328016 words/s, in_qsize 6, out_qsize 2\n",
            "2022-03-07 22:39:09,803 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:09,832 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:09,839 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:09,841 : - EPOCH - 23 : training on 597929 raw words (502777 effective words) took 1.4s, 348994 effective words/s\n",
            "2022-03-07 22:39:10,885 : - EPOCH 24 - PROGRESS: at 66.93% examples, 326628 words/s, in_qsize 3, out_qsize 2\n",
            "2022-03-07 22:39:11,287 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:11,302 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:11,325 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:11,327 : - EPOCH - 24 : training on 597929 raw words (502954 effective words) took 1.5s, 341647 effective words/s\n",
            "2022-03-07 22:39:12,363 : - EPOCH 25 - PROGRESS: at 68.61% examples, 339937 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:12,761 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:12,772 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:12,793 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:12,794 : - EPOCH - 25 : training on 597929 raw words (503004 effective words) took 1.4s, 347947 effective words/s\n",
            "2022-03-07 22:39:13,866 : - EPOCH 26 - PROGRESS: at 66.94% examples, 317579 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:39:14,253 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:14,266 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:14,280 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:14,282 : - EPOCH - 26 : training on 597929 raw words (502967 effective words) took 1.5s, 340841 effective words/s\n",
            "2022-03-07 22:39:15,324 : - EPOCH 27 - PROGRESS: at 68.60% examples, 334620 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:15,693 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:15,725 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:15,733 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:15,735 : - EPOCH - 27 : training on 597929 raw words (502752 effective words) took 1.4s, 349093 effective words/s\n",
            "2022-03-07 22:39:16,775 : - EPOCH 28 - PROGRESS: at 68.61% examples, 335106 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:17,176 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:17,185 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:17,205 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:17,207 : - EPOCH - 28 : training on 597929 raw words (502646 effective words) took 1.5s, 344388 effective words/s\n",
            "2022-03-07 22:39:18,267 : - EPOCH 29 - PROGRESS: at 68.60% examples, 329070 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:18,636 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:18,662 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:18,672 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:18,675 : - EPOCH - 29 : training on 597929 raw words (502912 effective words) took 1.5s, 345639 effective words/s\n",
            "2022-03-07 22:39:19,702 : - EPOCH 30 - PROGRESS: at 70.26% examples, 347567 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:20,069 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:20,081 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:20,099 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:20,101 : - EPOCH - 30 : training on 597929 raw words (503030 effective words) took 1.4s, 355369 effective words/s\n",
            "2022-03-07 22:39:20,104 : - training on a 17937870 raw words (15086653 effective words) took 44.6s, 338389 effective words/s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15086653, 17937870)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "id": "8GHYdEtiM4K1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f255d2c8-e252-483d-bd10-be8c2cb109fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:39:20,116 : - precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 0.5769424438476562),\n",
              " ('facebook', 0.551522433757782),\n",
              " ('uber', 0.4859882593154907),\n",
              " ('amazon', 0.48066601157188416),\n",
              " ('software', 0.4779198169708252),\n",
              " ('walmart', 0.4597754180431366),\n",
              " ('volkswagen', 0.45836687088012695),\n",
              " ('snapchat', 0.45630669593811035),\n",
              " ('yahoo', 0.45258331298828125),\n",
              " ('waze', 0.44571492075920105)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"microsoft\")"
      ],
      "metadata": {
        "id": "wTIyNyZ1M51L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79970594-9b3d-415e-a213-b6b9a1b41aab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amazon', 0.5997419953346252),\n",
              " ('unilever', 0.5724723935127258),\n",
              " ('tesla', 0.5651404857635498),\n",
              " ('sony', 0.5616632699966431),\n",
              " ('sky', 0.5525799989700317),\n",
              " ('canais', 0.5414109826087952),\n",
              " ('walmart', 0.5260538458824158),\n",
              " ('ford', 0.520609974861145),\n",
              " ('lego', 0.5149815678596497),\n",
              " ('braskem', 0.5143789649009705)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"barcelona\")"
      ],
      "metadata": {
        "id": "nnHcbwWIM6xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa793b6-cb9c-43ae-cadd-fd4376e757e4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('psg', 0.6068384647369385),\n",
              " ('barça', 0.5947757959365845),\n",
              " ('bayern', 0.5686943531036377),\n",
              " ('chelsea', 0.567247748374939),\n",
              " ('juventus', 0.5637489557266235),\n",
              " ('united', 0.5602964162826538),\n",
              " ('figueirense', 0.5567421913146973),\n",
              " ('leicester', 0.5475366115570068),\n",
              " ('monaco', 0.5414623022079468),\n",
              " ('madrid', 0.539014458656311)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"messi\")"
      ],
      "metadata": {
        "id": "7RD95eYOM7nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7c3196-e93f-41b2-8b66-47050725f825"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suárez', 0.5877499580383301),\n",
              " ('neymar', 0.555770754814148),\n",
              " ('cristiano', 0.5375217795372009),\n",
              " ('tevez', 0.5229377746582031),\n",
              " ('ronaldo', 0.5074933767318726),\n",
              " ('cavani', 0.5020517110824585),\n",
              " ('barcelona', 0.49741482734680176),\n",
              " ('benzema', 0.4915468096733093),\n",
              " ('chuteiras', 0.48316478729248047),\n",
              " ('enrique', 0.483090877532959)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "id": "qvgfWlCiM8ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37523c21-1183-425a-8fdc-d2825745849b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chrysler', 0.6860479116439819),\n",
              " ('volks', 0.646731972694397),\n",
              " ('honda', 0.6461108922958374),\n",
              " ('toyota', 0.6358920931816101),\n",
              " ('volkswagen', 0.6198612451553345),\n",
              " ('embraer', 0.6157119274139404),\n",
              " ('renault', 0.6105237007141113),\n",
              " ('braskem', 0.6017100811004639),\n",
              " ('tesla', 0.587050199508667),\n",
              " ('sony', 0.5863809585571289)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinamento do modelo Skip-Gram\n",
        "w2v_modelo_sg = Word2Vec(sg = 1,\n",
        "                      window = 5,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
        "\n",
        "w2v_modelo_sg.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo_sg.corpus_count,\n",
        "                 epochs = 30)"
      ],
      "metadata": {
        "id": "4BQ-BHCZM9Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbed46a6-08de-4ac8-da08-a7479cc59c1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:39:20,300 : - collecting all words and their counts\n",
            "2022-03-07 22:39:20,305 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-03-07 22:39:20,327 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2022-03-07 22:39:20,349 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2022-03-07 22:39:20,372 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2022-03-07 22:39:20,394 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2022-03-07 22:39:20,411 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2022-03-07 22:39:20,428 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2022-03-07 22:39:20,445 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2022-03-07 22:39:20,463 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2022-03-07 22:39:20,482 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2022-03-07 22:39:20,497 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2022-03-07 22:39:20,516 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2022-03-07 22:39:20,535 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2022-03-07 22:39:20,551 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2022-03-07 22:39:20,569 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2022-03-07 22:39:20,586 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2022-03-07 22:39:20,605 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2022-03-07 22:39:20,621 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2022-03-07 22:39:20,629 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2022-03-07 22:39:20,631 : - Loading a fresh vocabulary\n",
            "2022-03-07 22:39:20,680 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2022-03-07 22:39:20,682 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2022-03-07 22:39:20,727 : - deleting the raw counts dictionary of 39968 items\n",
            "2022-03-07 22:39:20,731 : - sample=0.001 downsamples 11 most-common words\n",
            "2022-03-07 22:39:20,733 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2022-03-07 22:39:20,799 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2022-03-07 22:39:20,800 : - resetting layer weights\n",
            "2022-03-07 22:39:23,734 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
            "2022-03-07 22:39:24,769 : - EPOCH 1 - PROGRESS: at 26.80% examples, 131612 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:25,797 : - EPOCH 1 - PROGRESS: at 53.59% examples, 131269 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:26,859 : - EPOCH 1 - PROGRESS: at 81.95% examples, 132372 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:27,372 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:27,410 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:27,443 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:27,445 : - EPOCH - 1 : training on 597929 raw words (503022 effective words) took 3.7s, 136017 effective words/s\n",
            "2022-03-07 22:39:28,472 : - EPOCH 2 - PROGRESS: at 25.13% examples, 124381 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:29,492 : - EPOCH 2 - PROGRESS: at 53.59% examples, 132211 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:30,505 : - EPOCH 2 - PROGRESS: at 81.95% examples, 135217 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:31,001 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:31,070 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:31,090 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:31,093 : - EPOCH - 2 : training on 597929 raw words (503021 effective words) took 3.6s, 138341 effective words/s\n",
            "2022-03-07 22:39:32,110 : - EPOCH 3 - PROGRESS: at 26.80% examples, 133910 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:33,190 : - EPOCH 3 - PROGRESS: at 55.26% examples, 133118 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:34,246 : - EPOCH 3 - PROGRESS: at 85.30% examples, 136539 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:34,660 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:34,714 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:34,737 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:34,738 : - EPOCH - 3 : training on 597929 raw words (503042 effective words) took 3.6s, 138428 effective words/s\n",
            "2022-03-07 22:39:35,808 : - EPOCH 4 - PROGRESS: at 26.80% examples, 127528 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:36,867 : - EPOCH 4 - PROGRESS: at 55.26% examples, 131254 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:37,941 : - EPOCH 4 - PROGRESS: at 85.30% examples, 134479 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:38,297 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:38,392 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:38,398 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:38,400 : - EPOCH - 4 : training on 597929 raw words (502846 effective words) took 3.6s, 137876 effective words/s\n",
            "2022-03-07 22:39:39,467 : - EPOCH 5 - PROGRESS: at 26.80% examples, 128137 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:40,522 : - EPOCH 5 - PROGRESS: at 56.93% examples, 135762 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:41,540 : - EPOCH 5 - PROGRESS: at 85.30% examples, 137273 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:41,948 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:41,962 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:41,976 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:41,977 : - EPOCH - 5 : training on 597929 raw words (502839 effective words) took 3.6s, 141252 effective words/s\n",
            "2022-03-07 22:39:43,017 : - EPOCH 6 - PROGRESS: at 26.80% examples, 131625 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:44,029 : - EPOCH 6 - PROGRESS: at 55.26% examples, 136350 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:45,065 : - EPOCH 6 - PROGRESS: at 83.63% examples, 136928 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:45,524 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:45,526 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:45,590 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:45,592 : - EPOCH - 6 : training on 597929 raw words (503067 effective words) took 3.6s, 139793 effective words/s\n",
            "2022-03-07 22:39:46,714 : - EPOCH 7 - PROGRESS: at 26.80% examples, 120881 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:47,728 : - EPOCH 7 - PROGRESS: at 55.26% examples, 130322 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:48,812 : - EPOCH 7 - PROGRESS: at 83.62% examples, 130866 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:49,227 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:49,266 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:49,295 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:49,297 : - EPOCH - 7 : training on 597929 raw words (502762 effective words) took 3.7s, 136019 effective words/s\n",
            "2022-03-07 22:39:50,338 : - EPOCH 8 - PROGRESS: at 26.80% examples, 131132 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:39:51,355 : - EPOCH 8 - PROGRESS: at 55.26% examples, 135754 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:52,373 : - EPOCH 8 - PROGRESS: at 83.62% examples, 137286 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:52,814 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:52,855 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:52,865 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:52,867 : - EPOCH - 8 : training on 597929 raw words (502814 effective words) took 3.6s, 141423 effective words/s\n",
            "2022-03-07 22:39:53,898 : - EPOCH 9 - PROGRESS: at 26.80% examples, 132256 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:54,965 : - EPOCH 9 - PROGRESS: at 55.26% examples, 133142 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:55,989 : - EPOCH 9 - PROGRESS: at 83.64% examples, 135227 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:39:56,445 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:39:56,534 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:39:56,554 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:39:56,556 : - EPOCH - 9 : training on 597929 raw words (503019 effective words) took 3.7s, 136823 effective words/s\n",
            "2022-03-07 22:39:57,628 : - EPOCH 10 - PROGRESS: at 26.80% examples, 127263 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:58,639 : - EPOCH 10 - PROGRESS: at 53.59% examples, 130026 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:39:59,752 : - EPOCH 10 - PROGRESS: at 83.63% examples, 132117 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:00,221 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:00,229 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:00,241 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:00,243 : - EPOCH - 10 : training on 597929 raw words (502944 effective words) took 3.7s, 136949 effective words/s\n",
            "2022-03-07 22:40:01,368 : - EPOCH 11 - PROGRESS: at 28.48% examples, 128645 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:02,373 : - EPOCH 11 - PROGRESS: at 55.26% examples, 131093 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:03,390 : - EPOCH 11 - PROGRESS: at 81.95% examples, 131461 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:03,873 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:03,910 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:03,936 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:03,938 : - EPOCH - 11 : training on 597929 raw words (502826 effective words) took 3.7s, 136580 effective words/s\n",
            "2022-03-07 22:40:05,031 : - EPOCH 12 - PROGRESS: at 26.80% examples, 124735 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:06,044 : - EPOCH 12 - PROGRESS: at 53.59% examples, 128583 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:07,085 : - EPOCH 12 - PROGRESS: at 81.95% examples, 131471 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:07,632 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:07,672 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:07,677 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:07,679 : - EPOCH - 12 : training on 597929 raw words (502822 effective words) took 3.7s, 134912 effective words/s\n",
            "2022-03-07 22:40:08,735 : - EPOCH 13 - PROGRESS: at 26.80% examples, 128931 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:09,847 : - EPOCH 13 - PROGRESS: at 56.95% examples, 132617 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:10,855 : - EPOCH 13 - PROGRESS: at 85.30% examples, 135499 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:11,200 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:11,305 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:11,315 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:11,318 : - EPOCH - 13 : training on 597929 raw words (502745 effective words) took 3.6s, 138648 effective words/s\n",
            "2022-03-07 22:40:12,466 : - EPOCH 14 - PROGRESS: at 28.48% examples, 125982 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:13,488 : - EPOCH 14 - PROGRESS: at 56.95% examples, 132530 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:14,512 : - EPOCH 14 - PROGRESS: at 85.28% examples, 134805 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:14,924 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:14,940 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:14,982 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:14,984 : - EPOCH - 14 : training on 597929 raw words (502940 effective words) took 3.7s, 137674 effective words/s\n",
            "2022-03-07 22:40:16,112 : - EPOCH 15 - PROGRESS: at 28.48% examples, 128582 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:40:17,203 : - EPOCH 15 - PROGRESS: at 58.61% examples, 133583 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:18,278 : - EPOCH 15 - PROGRESS: at 86.95% examples, 133365 words/s, in_qsize 6, out_qsize 1\n",
            "2022-03-07 22:40:18,594 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:18,607 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:18,636 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:18,638 : - EPOCH - 15 : training on 597929 raw words (503019 effective words) took 3.6s, 138255 effective words/s\n",
            "2022-03-07 22:40:19,726 : - EPOCH 16 - PROGRESS: at 26.80% examples, 124833 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:20,742 : - EPOCH 16 - PROGRESS: at 56.93% examples, 136454 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:21,811 : - EPOCH 16 - PROGRESS: at 85.28% examples, 135495 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:22,264 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:22,278 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:22,282 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:22,284 : - EPOCH - 16 : training on 597929 raw words (502854 effective words) took 3.6s, 138286 effective words/s\n",
            "2022-03-07 22:40:23,312 : - EPOCH 17 - PROGRESS: at 25.13% examples, 124523 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:40:24,340 : - EPOCH 17 - PROGRESS: at 55.26% examples, 135840 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:25,348 : - EPOCH 17 - PROGRESS: at 83.62% examples, 137772 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:25,845 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:25,853 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:25,880 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:25,881 : - EPOCH - 17 : training on 597929 raw words (502904 effective words) took 3.6s, 140313 effective words/s\n",
            "2022-03-07 22:40:26,945 : - EPOCH 18 - PROGRESS: at 26.80% examples, 128770 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:28,032 : - EPOCH 18 - PROGRESS: at 56.93% examples, 134018 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:29,109 : - EPOCH 18 - PROGRESS: at 88.61% examples, 138846 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:29,358 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:29,418 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:29,427 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:29,429 : - EPOCH - 18 : training on 597929 raw words (502918 effective words) took 3.5s, 142491 effective words/s\n",
            "2022-03-07 22:40:30,487 : - EPOCH 19 - PROGRESS: at 25.13% examples, 120936 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:31,497 : - EPOCH 19 - PROGRESS: at 55.26% examples, 135099 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:32,526 : - EPOCH 19 - PROGRESS: at 83.63% examples, 136378 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:32,994 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:33,020 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:33,043 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:33,044 : - EPOCH - 19 : training on 597929 raw words (502942 effective words) took 3.6s, 139639 effective words/s\n",
            "2022-03-07 22:40:34,115 : - EPOCH 20 - PROGRESS: at 26.80% examples, 127424 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:35,122 : - EPOCH 20 - PROGRESS: at 56.93% examples, 138448 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:36,130 : - EPOCH 20 - PROGRESS: at 85.28% examples, 139531 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:36,539 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:36,558 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:36,585 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:36,586 : - EPOCH - 20 : training on 597929 raw words (502760 effective words) took 3.5s, 142490 effective words/s\n",
            "2022-03-07 22:40:37,610 : - EPOCH 21 - PROGRESS: at 28.48% examples, 141379 words/s, in_qsize 6, out_qsize 0\n",
            "2022-03-07 22:40:38,676 : - EPOCH 21 - PROGRESS: at 58.61% examples, 141727 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:39,714 : - EPOCH 21 - PROGRESS: at 88.61% examples, 143035 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:39,970 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:40,058 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:40,078 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:40,080 : - EPOCH - 21 : training on 597929 raw words (502877 effective words) took 3.5s, 144484 effective words/s\n",
            "2022-03-07 22:40:41,112 : - EPOCH 22 - PROGRESS: at 26.80% examples, 132337 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:42,169 : - EPOCH 22 - PROGRESS: at 56.93% examples, 137783 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:43,197 : - EPOCH 22 - PROGRESS: at 86.96% examples, 140878 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:43,547 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:43,606 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:43,610 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:43,612 : - EPOCH - 22 : training on 597929 raw words (502712 effective words) took 3.5s, 142959 effective words/s\n",
            "2022-03-07 22:40:44,689 : - EPOCH 23 - PROGRESS: at 26.80% examples, 126700 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:45,705 : - EPOCH 23 - PROGRESS: at 55.26% examples, 133445 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:40:46,728 : - EPOCH 23 - PROGRESS: at 85.30% examples, 138264 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:47,153 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:47,161 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:47,199 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:47,200 : - EPOCH - 23 : training on 597929 raw words (503117 effective words) took 3.6s, 140723 effective words/s\n",
            "2022-03-07 22:40:48,249 : - EPOCH 24 - PROGRESS: at 26.80% examples, 129932 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:40:49,296 : - EPOCH 24 - PROGRESS: at 56.95% examples, 137193 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:50,413 : - EPOCH 24 - PROGRESS: at 88.62% examples, 139217 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:50,632 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:50,716 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:50,729 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:50,730 : - EPOCH - 24 : training on 597929 raw words (502924 effective words) took 3.5s, 142950 effective words/s\n",
            "2022-03-07 22:40:51,799 : - EPOCH 25 - PROGRESS: at 26.80% examples, 128089 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:52,852 : - EPOCH 25 - PROGRESS: at 56.95% examples, 135859 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:40:53,884 : - EPOCH 25 - PROGRESS: at 88.61% examples, 142027 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:54,173 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:54,205 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:54,250 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:54,251 : - EPOCH - 25 : training on 597929 raw words (503077 effective words) took 3.5s, 143530 effective words/s\n",
            "2022-03-07 22:40:55,322 : - EPOCH 26 - PROGRESS: at 28.48% examples, 135152 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:56,332 : - EPOCH 26 - PROGRESS: at 58.61% examples, 142312 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:57,393 : - EPOCH 26 - PROGRESS: at 88.61% examples, 142400 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:57,614 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:40:57,697 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:40:57,700 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:40:57,705 : - EPOCH - 26 : training on 597929 raw words (502956 effective words) took 3.4s, 146176 effective words/s\n",
            "2022-03-07 22:40:58,724 : - EPOCH 27 - PROGRESS: at 26.80% examples, 133563 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:40:59,820 : - EPOCH 27 - PROGRESS: at 58.60% examples, 139912 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:00,910 : - EPOCH 27 - PROGRESS: at 88.61% examples, 139511 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:41:01,131 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:41:01,178 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:41:01,214 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:41:01,215 : - EPOCH - 27 : training on 597929 raw words (502998 effective words) took 3.5s, 143749 effective words/s\n",
            "2022-03-07 22:41:02,269 : - EPOCH 28 - PROGRESS: at 26.80% examples, 130263 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:03,295 : - EPOCH 28 - PROGRESS: at 56.93% examples, 138759 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:04,354 : - EPOCH 28 - PROGRESS: at 85.28% examples, 137412 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:41:04,686 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:41:04,696 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:41:04,761 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:41:04,762 : - EPOCH - 28 : training on 597929 raw words (502736 effective words) took 3.5s, 142547 effective words/s\n",
            "2022-03-07 22:41:05,799 : - EPOCH 29 - PROGRESS: at 28.48% examples, 139621 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:06,913 : - EPOCH 29 - PROGRESS: at 58.61% examples, 137556 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:07,934 : - EPOCH 29 - PROGRESS: at 88.61% examples, 140990 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:08,126 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:41:08,219 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:41:08,248 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:41:08,249 : - EPOCH - 29 : training on 597929 raw words (502965 effective words) took 3.5s, 144729 effective words/s\n",
            "2022-03-07 22:41:09,274 : - EPOCH 30 - PROGRESS: at 26.80% examples, 133546 words/s, in_qsize 4, out_qsize 1\n",
            "2022-03-07 22:41:10,342 : - EPOCH 30 - PROGRESS: at 58.61% examples, 141686 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:11,426 : - EPOCH 30 - PROGRESS: at 88.62% examples, 140964 words/s, in_qsize 5, out_qsize 0\n",
            "2022-03-07 22:41:11,630 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-03-07 22:41:11,714 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-07 22:41:11,732 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-07 22:41:11,734 : - EPOCH - 30 : training on 597929 raw words (502923 effective words) took 3.5s, 145026 effective words/s\n",
            "2022-03-07 22:41:11,736 : - training on a 17937870 raw words (15087391 effective words) took 108.0s, 139697 effective words/s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15087391, 17937870)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "id": "jt2mhRORM-JM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869f8f47-3e7c-4caf-86f2-5b47986f28e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:41:11,749 : - precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reguladores', 0.45178472995758057),\n",
              " ('apple', 0.4187764823436737),\n",
              " ('android', 0.3953913748264313),\n",
              " ('buffett', 0.3885148763656616),\n",
              " ('yahoo', 0.38758838176727295),\n",
              " ('anunciantes', 0.37553176283836365),\n",
              " ('verizon', 0.37003111839294434),\n",
              " ('automóveis', 0.3609682023525238),\n",
              " ('waze', 0.35871025919914246),\n",
              " ('intel', 0.356596440076828)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "id": "zrb_fZ3iNAHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8e8984-3221-4257-ac46-1dda604aa07b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 0.5769424438476562),\n",
              " ('facebook', 0.551522433757782),\n",
              " ('uber', 0.4859882593154907),\n",
              " ('amazon', 0.48066601157188416),\n",
              " ('software', 0.4779198169708252),\n",
              " ('walmart', 0.4597754180431366),\n",
              " ('volkswagen', 0.45836687088012695),\n",
              " ('snapchat', 0.45630669593811035),\n",
              " ('yahoo', 0.45258331298828125),\n",
              " ('waze', 0.44571492075920105)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "id": "ytb9XWShNBKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d514f447-0426-4e97-c576-4c9dbb62ed30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('metalúrgicos', 0.5842881202697754),\n",
              " ('motors', 0.5222570896148682),\n",
              " ('audi', 0.5042167901992798),\n",
              " ('cubatão', 0.4997138977050781),\n",
              " ('honda', 0.4948770999908447),\n",
              " ('bmw', 0.4737921357154846),\n",
              " ('mitsubishi', 0.4659489393234253),\n",
              " ('fiat', 0.4644043743610382),\n",
              " ('autoguiados', 0.46154266595840454),\n",
              " ('airbag', 0.45815417170524597)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "id": "xgwJBPxINCY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff902271-4ab5-4d98-9482-18d0f1c34d30"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chrysler', 0.6860479116439819),\n",
              " ('volks', 0.646731972694397),\n",
              " ('honda', 0.6461108922958374),\n",
              " ('toyota', 0.6358920931816101),\n",
              " ('volkswagen', 0.6198612451553345),\n",
              " ('embraer', 0.6157119274139404),\n",
              " ('renault', 0.6105237007141113),\n",
              " ('braskem', 0.6017100811004639),\n",
              " ('tesla', 0.587050199508667),\n",
              " ('sony', 0.5863809585571289)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.save_word2vec_format(\"modelo_cbow.txt\", binary=False)\n",
        "w2v_modelo_sg.wv.save_word2vec_format(\"modelo_skipgram.txt\", binary=False)"
      ],
      "metadata": {
        "id": "HtA-UtSSNDdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefdd1d4-bd41-4b76-cf0b-0fd9922723c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:41:11,847 : - storing 13006x300 projection weights into modelo_cbow.txt\n",
            "2022-03-07 22:41:14,613 : - storing 13006x300 projection weights into modelo_skipgram.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vetorizando treino e teste"
      ],
      "metadata": {
        "id": "L7aq_s53OMOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "ADt3eoBeOsvZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo_cbow = KeyedVectors.load_word2vec_format(\"modelo_cbow.txt\")\n",
        "w2v_modelo_sg = KeyedVectors.load_word2vec_format(\"modelo_skipgram.txt\")\n",
        "artigo_treino = dados_treino\n",
        "artigo_teste = dados_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TItZeyFZOWtM",
        "outputId": "2a7c4917-a831-4719-d1e8-12c2fef4d712"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-07 22:41:17,334 : - loading projection weights from modelo_cbow.txt\n",
            "2022-03-07 22:41:19,595 : - loaded (13006, 300) matrix from modelo_cbow.txt\n",
            "2022-03-07 22:41:19,596 : - loading projection weights from modelo_skipgram.txt\n",
            "2022-03-07 22:41:21,928 : - loaded (13006, 300) matrix from modelo_skipgram.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"paser\", \"ner\", \"tagger\", \"textcat\"])\n",
        "\n",
        "def tokenizador(texto):\n",
        "    \n",
        "    doc = nlp(texto)\n",
        "    tokens_validos = []\n",
        "    for token in doc:\n",
        "        e_valido = not token.is_stop and token.is_alpha\n",
        "        if e_valido:\n",
        "            tokens_validos.append(token.text.lower())\n",
        "\n",
        "    \n",
        "    return  tokens_validos\n",
        "\n",
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "tokens = tokenizador(texto)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QShnDAcOnJJ",
        "outputId": "5f569529-9a0e-4894-99f7-f4a5e25f6e79"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio', 'janeiro', 'cidade', 'maravilhosa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combinacao_de_vetores_por_soma(palavras, modelo):\n",
        "\n",
        "    vetor_resultante = np.zeros((1,300))\n",
        "\n",
        "    for pn in palavras:\n",
        "        try:\n",
        "            vetor_resultante += modelo.get_vector(pn)\n",
        "\n",
        "        except KeyError:\n",
        "            pass\n",
        "                \n",
        "\n",
        "    return vetor_resultante\n",
        "\n",
        "vetor_texto = combinacao_de_vetores_por_soma(tokens, w2v_modelo_cbow)\n",
        "print(vetor_texto.shape)\n",
        "print(vetor_texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-16_mC_OnO3",
        "outputId": "774610f8-22d7-45b3-b7aa-a19bd6f92fda"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 300)\n",
            "[[-5.39423032e-02  2.05666050e-01  5.61055720e-01  7.94501007e-02\n",
            "   7.88361818e-01 -1.98687884e+00  1.09880002e+00  8.35407436e-01\n",
            "  -1.67026201e+00 -3.02382525e-01 -4.03450876e-01 -2.71810845e+00\n",
            "  -9.40536499e-01  1.94282454e+00  6.00015432e-01  4.71153766e-01\n",
            "   1.54639032e+00  1.08005215e-01 -3.11272196e-01 -2.15721226e+00\n",
            "  -6.72993600e-01 -4.67150547e-01  2.10443613e+00 -2.01361774e+00\n",
            "  -2.52699547e-01 -1.93549949e+00 -2.44662535e+00  1.20902634e+00\n",
            "   4.26059009e-01 -2.28288782e+00 -1.55009404e-02  2.13869339e+00\n",
            "  -9.68052596e-02  1.52843118e+00  7.68015465e-01  3.56920719e-01\n",
            "   7.37850472e-01  1.54942555e+00  8.12472098e-01  9.01347056e-01\n",
            "   1.56365925e+00 -5.51601946e-02  1.20413458e+00 -1.44400117e+00\n",
            "   1.24045267e+00  1.55836654e+00  7.30244085e-01 -3.65597445e+00\n",
            "   1.58766720e+00 -2.14718971e-01 -7.61160731e-01 -3.99800575e+00\n",
            "  -6.13810629e-01 -1.15358061e+00 -8.61807615e-01 -1.85132340e+00\n",
            "   2.21819620e+00 -9.86089051e-01 -6.85825005e-01 -5.46040151e-01\n",
            "  -6.79179788e-01 -7.34138317e-01  1.21566886e+00 -2.93004178e-01\n",
            "   1.91923715e-02  2.12442726e-01 -1.76976554e-01 -1.72769798e+00\n",
            "   2.07787931e+00 -4.38791662e-02  7.61484876e-01 -3.85350394e-02\n",
            "  -2.12015040e+00  1.27565019e+00  4.96726438e-01  4.95257378e-01\n",
            "   2.25327748e+00 -1.29518288e+00  1.23149902e-02  4.05450910e-02\n",
            "   2.67154452e+00  7.04202592e-01  2.64924192e+00  2.99138993e+00\n",
            "   1.90495497e+00  8.89840484e-01  1.35809302e+00  1.41724233e+00\n",
            "   1.82224232e+00 -2.02186631e+00 -1.01480843e+00 -6.83140501e-01\n",
            "   1.25415465e+00 -3.50698286e+00  2.72287178e+00  7.69563794e-01\n",
            "  -5.90525143e-01 -4.34876084e-01  1.56994247e+00 -3.30805324e-01\n",
            "   1.20625026e+00 -3.84857953e-01 -8.37150948e-01 -1.10607801e+00\n",
            "   3.93908210e-01 -3.85269972e-01  1.16696140e+00 -2.77901578e+00\n",
            "  -7.34343714e-01 -2.29865551e+00 -1.59230665e+00  8.54924157e-01\n",
            "   7.44297504e-01 -1.63846248e+00  1.59116720e+00  4.53570417e-01\n",
            "   5.11154331e-01  1.02294657e+00 -4.01076853e-01  1.92672682e+00\n",
            "  -9.32748483e-01 -6.18994206e-01 -6.13603517e-01 -3.15224057e+00\n",
            "   1.57581484e+00  6.02718145e-02  2.19398767e+00 -1.23009766e+00\n",
            "   6.65888563e-01 -2.68961981e+00  2.65292078e-01 -8.11572865e-01\n",
            "   4.80244666e-01  1.43293868e+00  2.35202238e-01 -1.58715367e-01\n",
            "   3.80316302e-01 -1.33108318e-01 -1.39431474e+00 -8.85557771e-01\n",
            "  -9.94596217e-01  7.54438442e-01 -2.22615682e-01 -3.88501868e-01\n",
            "  -1.60434410e+00 -1.84817129e+00 -1.25767259e+00  5.81211448e-01\n",
            "   2.00364578e+00  1.20823413e-01  3.39665622e-01 -2.91220522e+00\n",
            "   1.69371065e+00 -4.59555037e-01  1.03068993e+00  3.45222026e-01\n",
            "   6.50276005e-01  1.27434216e+00 -2.63395011e-01 -1.17489125e+00\n",
            "  -2.55386388e+00  8.73097703e-01  8.19312371e-02  6.24410212e-01\n",
            "  -8.41520727e-04 -2.32850796e+00  4.07105580e-01  5.44759158e-01\n",
            "   9.30282116e-01 -7.29059570e-01  1.91191137e-01 -7.62377709e-01\n",
            "   4.49845195e-02  4.59297258e-01 -1.50650446e+00  1.72276748e-01\n",
            "  -1.90240994e-01  2.01352927e+00  1.11029875e+00 -1.63995708e+00\n",
            "  -5.63125253e-01  3.95222876e-01  3.35724643e+00  4.41718340e-01\n",
            "  -3.97724964e-01  3.34530771e-01  1.52274426e-01 -1.31053632e+00\n",
            "   2.48164052e+00 -2.92898351e+00  1.45359716e+00 -1.06736897e+00\n",
            "   6.00736499e-01 -6.72045708e-01  7.77660728e-01 -2.64491662e-01\n",
            "  -1.37000674e+00  2.23382251e+00  8.90649751e-01 -6.61309123e-01\n",
            "   2.12587118e-02 -1.25509083e+00  1.58193111e-01  1.34315284e+00\n",
            "   1.00012004e-01  7.21392781e-01 -1.01033882e+00  9.75087941e-01\n",
            "   1.83191642e+00  1.36975121e+00  1.09770039e+00  1.48688701e+00\n",
            "   1.58968678e+00  2.18756566e+00 -8.89436342e-01 -1.69148690e+00\n",
            "  -1.86939821e+00 -2.95155734e-01 -2.41240866e-01 -1.08275065e+00\n",
            "  -6.17980421e-01  2.74361536e+00  7.22466141e-01  2.91598856e-01\n",
            "  -1.48508668e+00  7.61784513e-01 -7.85159171e-01 -2.53229225e+00\n",
            "   4.37774852e-01 -7.46298701e-01 -1.34150206e+00 -1.00390024e+00\n",
            "   4.34292734e-01 -6.08591605e-01 -1.19675808e+00  1.08420543e-01\n",
            "   5.62003508e-01  9.12323415e-01  1.03017181e-01  1.46088597e+00\n",
            "  -6.31859258e-01 -1.01157051e-01  1.17186093e+00 -9.25431013e-01\n",
            "   1.46432154e-01 -5.85253119e-01  3.64560366e-01 -2.23535529e+00\n",
            "   8.50164890e-01  3.14217389e-01  3.88035649e+00 -1.71724170e-01\n",
            "   1.61812752e-01  4.33004856e-01  7.15484649e-01 -3.26020718e-01\n",
            "  -5.61152697e-02  5.19580737e-01  8.86678398e-01 -1.51054680e-01\n",
            "   2.66866404e+00 -3.15814179e+00 -2.10758395e+00  7.39642650e-01\n",
            "  -1.79014151e+00  5.86632639e-02  1.28466292e+00  2.10442458e+00\n",
            "  -1.00361437e-01 -2.35400230e+00 -8.28174025e-01 -1.33937404e+00\n",
            "   4.16065916e-01 -1.01384127e+00 -4.69072256e-02  1.76954269e-02\n",
            "  -7.51802765e-01 -2.92183816e+00 -4.46392393e-01 -1.06871486e-01\n",
            "  -1.19872640e-01  2.27130318e+00 -1.67644246e+00  1.79003611e-01\n",
            "   1.80530396e+00 -1.44187123e-01  3.32000059e+00 -1.12088308e+00\n",
            "   2.74063396e+00 -1.30369529e-01  6.24231398e-02 -1.66745631e+00\n",
            "  -1.99821171e+00 -4.12285388e-01 -9.42284524e-01 -1.41081898e+00\n",
            "   1.45517372e-01 -3.95924121e-01  2.44458771e+00 -4.12657708e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matriz_vetores(textos, modelo):\n",
        "    x = len(textos)\n",
        "    y = 300\n",
        "    matriz = np.zeros((x,y))\n",
        "\n",
        "    for i in range(x):\n",
        "        palavras = tokenizador(textos.iloc[i])\n",
        "        matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo)\n",
        "\n",
        "    return matriz\n",
        "\n",
        "matriz_vetores_treino_cbow = matriz_vetores(artigo_treino.title, w2v_modelo_cbow)\n",
        "matriz_vetores_teste_cbow = matriz_vetores(artigo_teste.title, w2v_modelo_cbow)\n",
        "print(matriz_vetores_treino_cbow.shape)\n",
        "print(matriz_vetores_teste_cbow.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26GoRxOhOnSt",
        "outputId": "b6334b35-b44d-4167-86df-3ccec0161f37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino e integração classificador"
      ],
      "metadata": {
        "id": "gzHCcAhwOPbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def classificador(modelo, x_treino, y_treino, x_teste, y_teste):\n",
        "\n",
        "    RL = LogisticRegression(max_iter = 800)\n",
        "    RL.fit(x_treino, y_treino)\n",
        "    categorias = RL.predict(x_teste)\n",
        "    resultados = classification_report(y_teste, categorias)\n",
        "    print(resultados)\n",
        "    \n",
        "    return RL\n",
        "\n",
        "RL_cbow = classificador(w2v_modelo_cbow,\n",
        "                        matriz_vetores_treino_cbow,\n",
        "                        artigo_treino.category,\n",
        "                        matriz_vetores_teste_cbow,\n",
        "                        artigo_teste.category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apIy1P8zOS5_",
        "outputId": "1564bc76-dc16-441f-dc39-bb6f1f7e3799"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.81      0.71      0.76      6103\n",
            "   cotidiano       0.63      0.80      0.70      1698\n",
            "     esporte       0.92      0.86      0.89      4663\n",
            "   ilustrada       0.13      0.86      0.23       131\n",
            "     mercado       0.83      0.78      0.81      5867\n",
            "       mundo       0.74      0.83      0.78      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.68      0.81      0.70     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_vetores_treino_sg = matriz_vetores(artigo_treino.title, w2v_modelo_sg)\n",
        "matriz_vetores_teste_sg = matriz_vetores(artigo_teste.title, w2v_modelo_sg)\n",
        "\n",
        "RL_sg = classificador(w2v_modelo_sg,\n",
        "                        matriz_vetores_treino_sg,\n",
        "                        artigo_treino.category,\n",
        "                        matriz_vetores_teste_sg,\n",
        "                        artigo_teste.category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlwRGIoGO3Wn",
        "outputId": "0a4739c8-3ffa-4446-a640-5be059336722"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.81      0.71      0.76      6103\n",
            "   cotidiano       0.64      0.80      0.71      1698\n",
            "     esporte       0.93      0.87      0.90      4663\n",
            "   ilustrada       0.14      0.85      0.24       131\n",
            "     mercado       0.84      0.79      0.82      5867\n",
            "       mundo       0.75      0.84      0.79      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.69      0.81      0.70     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"rl_cbow.pkl\", \"wb\") as f:\n",
        "    pickle.dump(RL_cbow, f)"
      ],
      "metadata": {
        "id": "508_--gcO4Z_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rl_sg.pkl\", \"wb\") as f:\n",
        "    pickle.dump(RL_sg, f)"
      ],
      "metadata": {
        "id": "-4sPyij_O6qm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wq7dID-IO8jA"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}