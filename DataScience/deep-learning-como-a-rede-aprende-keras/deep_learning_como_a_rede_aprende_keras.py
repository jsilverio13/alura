# -*- coding: utf-8 -*-
"""deep-learning-como-a-rede-aprende-keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tvzwPc64aqH-ZDd_zgcifD6fxmoVr-0m

# Imports
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import load_model

import numpy as np
import matplotlib.pyplot as plt

"""# Carregando o DataSet"""

dataset = tf.keras.datasets.fashion_mnist
((imagens_treino,identificacoes_treino),(imagens_teste, identificacoes_teste  )) = dataset.load_data()

"""# Explorar os dados"""

imagens_treino.shape

imagens_teste.shape

identificacoes_treino.shape

identificacoes_teste.shape

total_de_classificacoes = len(np.unique(identificacoes_treino))
total_de_classificacoes

nomes_de_classificacoes = ['Camiseta', 'Calça', 'Pullover', 'Vestido', 'Casaco','Sandália','Camisa', 'Tênis','Bolsa','Bota']
nomes_de_classificacoes

"""# Exibir os dados"""

for imagem in range(10):
    plt.subplot(2, 5, imagem+1)
    plt.imshow(imagens_treino[imagem])
    plt.title(nomes_de_classificacoes[identificacoes_treino[imagem]])
    plt.colorbar()

"""# Normalizando as imagens"""

imagens_treino = imagens_treino/float(255)

"""# Criando, compilando, treinando e normalizando o modelo"""

modelo = keras.Sequential([ 
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(256, activation=tf.nn.relu),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10, activation=tf.nn.softmax),
])
callbacks = [
                keras.callbacks.EarlyStopping(monitor='val_loss'),
                keras.callbacks.ModelCheckpoint(filepath='melhor_modelo.hdf5',  monitor='val_loss', save_best_only=True)
            ]
adam = keras.optimizers.Adam(lr=0.002)

modelo.compile(optimizer=adam, 
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])


historico = modelo.fit(
    imagens_treino, 
    identificacoes_treino, 
    batch_size = None, 
    epochs=5, 
    validation_split=0.2,
    callbacks = callbacks)

"""## Resumo do modelo"""

sumario_modelo = modelo.summary()

"""## Pesos da primeira camada dense"""

pesos_camada_dense = modelo.layers[1].get_weights()[0]
pesos_camada_dense

modelo.compile(optimizer='adam', 
               loss='sparse_categorical_crossentropy',
               metrics=['accuracy'])


historico = modelo.fit(imagens_treino, identificacoes_treino, epochs=5, validation_split=0.2)

plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('Acuracia por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend(['treino', 'avaliação'])

plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('Acuracia por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend(['treino', 'avaliação'])

vieses_camada_dense = modelo.layers[1].get_weights()[1]
vieses_camada_dense

pesos_camada_dense_zerados = np.zeros(pesos_camada_dense.shape)
modelo.layers[1].set_weights([pesos_camada_dense_zerados, vieses_camada_dense])
modelo.layers[1].get_weights()[0]

vieses_camada_dense_zerados = np.zeros(vieses_camada_dense.shape)
modelo.layers[1].set_weights([pesos_camada_dense_zerados, vieses_camada_dense_zerados])

"""# Salvando e carregando o modelo treinado"""

pesos_camada_dense_aleatorios = np.random.rand(784,256)
modelo.layers[1].set_weights([pesos_camada_dense_aleatorios, vieses_camada_dense])
modelo.layers[1].get_weights()[0]

modelo.save('modelo.h5')
modelo_salvo = load_model('modelo.h5')

"""# Visualizando as acurácias de treino e validação por Época"""

plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('Acuracia por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend(['treino', 'avaliação'])

"""# Visualizando as perdas de treino e validação por Época"""

plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('Acuracia por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend(['treino', 'avaliação'])

"""# Testando o modelo e o modelo salvo"""

testes = modelo.predict(imagens_teste)
testes_modelo_salvo = modelo_salvo.predict(imagens_teste)

print(f'Resultado do teste: {np.argmax(testes[2])}')
print(f'Número da imagem de teste: {identificacoes_teste[2]}')

"""# Avaliando os modelos"""

perda_teste, acuracia_teste = modelo.evaluate(imagens_teste, identificacoes_teste)
perda_teste_salvo, acuracia_teste_salvo = modelo_salvo.evaluate(imagens_teste, identificacoes_teste)

print(f'Perda do teste: {perda_teste:.2f}')
print(f'Acurácia do teste: {acuracia_teste:.2f}')
print(f'Perda do teste salvo: {perda_teste_salvo:.2f}')
print(f'Acurácia do teste salvo: {acuracia_teste_salvo:.2f}')

